import sys
import numpy as np
import pandas as pd

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
from make_model import make_model

def from_txt_to_csv(file_name, folder_name):
    """
    Transform the output of the read_results_predict.py in a proper Kaggle Submission, i.e : a well formated csv file
    
    inputs : 
    - file_name is the name (string) of the txt file generated by the read_results_predict.py (without the .txt extension)
    - folder_name is the desired or existing name (string) of the folder where the submission will be stored 
    output : None
    """
    path_root = os.path.dirname(os.path.dirname(os.path.abspath('').replace('\\', '/')))
    path_to_data = path_root + '/data/'
    path_file = path_to_data + file_name + ".txt"
    path_folder = path_root + folder_name
    # create a directory if it doesn't exist yet
    if not os.path.exists(path_folder):
        os.makedirs(path_folder)
      
    df = pd.read_csv(path_file)
    df.to_csv(path_folder + "/" + file_name + ".csv", index=False)
    print("Submission saved in '{}'".format(path_folder))

def predict(folder_name):
    is_GPU = True
    path_root = os.path.dirname(os.path.dirname(os.path.abspath('').replace('\\', '/')))
    path_to_data = path_root + '/data/'
    path_to_code = path_root + '/repo/code/'
    sys.path.insert(0, path_to_code)
    
    docs = np.load(path_to_data + 'documents.npy')
    embeddings = np.load(path_to_data + 'embeddings.npy')
    
    with open(path_to_data + 'train_idxs.txt', 'r') as file:
        train_idxs = file.read().splitlines()
    
    with open(path_to_data + 'test_idxs.txt', 'r') as file:
        test_idxs = file.read().splitlines()
    
    train_idxs = [int(elt) for elt in train_idxs]
    test_idxs = [int(elt) for elt in test_idxs]
    
    docs_test = docs[test_idxs,:,:]
    
    all_preds_han = []
    
    for tgt in range(4):
        # relevant hyper-parameters
        n_units = 60
        drop_rate = 0 # prediction mode
        
        with open(path_to_data + 'targets/train/target_' + str(tgt) + '.txt', 'r') as file:
            target = file.read().splitlines()
        
        target = np.array(target).astype('float')
        
        model = make_model(n_units, drop_rate, embeddings, docs_test, is_GPU)
        
        model.load_weights(path_to_data + 'model_' + str(tgt))
        all_preds_han.append(model.predict(docs_test).tolist())
    
    # flatten
    all_preds_han = [elt[0] for sublist in all_preds_han for elt in sublist]
    
    with open(path_to_data + 'predictions_han.txt', 'w') as file:
        file.write('id,pred\n')
        for idx,pred in enumerate(all_preds_han):
            pred = format(pred, '.7f')
            file.write(str(idx) + ',' + pred + '\n')
            
    #from_txt_to_csv('predictions_han', folder_name)
    
predict('test')