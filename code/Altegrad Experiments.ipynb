{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altegrad Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#embeddings = np.load('D:\\Scolaire\\Code\\Python\\Machine Learning\\Kaggle Challenges M2\\Altegrad - Graphs HAN\\data\\embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1685895, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python main_baseline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference using trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python read_results_predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def from_txt_to_csv(file_name, folder_name):\n",
    "    \"\"\"\n",
    "    Transform the output of the read_results_predict.py in a proper Kaggle Submission, i.e : a well formated csv file\n",
    "    \n",
    "    inputs : \n",
    "    - file_name is the name (string) of the txt file generated by the read_results_predict.py (without the .txt extension)\n",
    "    - folder_name is the desired or existing name (string) of the folder where the submission will be stored into \n",
    "    \n",
    "    output : None\n",
    "    \n",
    "    \"\"\"\n",
    "    # change me !\n",
    "    path_root = 'D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/'\n",
    "    path_file = path_root + file_name + \".txt\"\n",
    "    path_folder = path_root + folder_name\n",
    "    # create a directory if it doesn't exist yet\n",
    "    if not os.path.exists(path_folder):\n",
    "        os.makedirs(path_folder)\n",
    "      \n",
    "    df = pd.read_csv(path_file)\n",
    "    df.to_csv(path_folder + \"/\" + file_name + \".csv\", index=False)\n",
    "    print(\"Submission saved in '{}'\".format(path_folder))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved in 'D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/exp_layers'\n"
     ]
    }
   ],
   "source": [
    "from_txt_to_csv('predictions_han', 'exp_layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep walk nous donne un fichier .embeddings contenant un en tête (?)\n",
    "et une liste de la forme numéro_du_noeud - vecteur representant l'embedding\n",
    "\n",
    "Il faut trouver un moyen de calculer ça pour tous les fichiers et de stocker le résultat final dans une grande matrice où numero du noeud = ligne matrice embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# for i in range(0, 93719): \n",
    "#         input_dest = \"D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/edge_lists/\" + str(i) + \".txt\" \n",
    "#         output_dest = \"./embeddings/emb\" + str(i) + \".embeddings\" \n",
    "#         os.system(\"deepwalk --format edgelist --workers 20 --input \"+ input_dest +\" --output \" + output_dest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "9372\n",
      "18744\n",
      "28116\n",
      "37488\n",
      "46860\n",
      "56232\n",
      "65604\n",
      "74976\n",
      "84348\n",
      "documents generated\n",
      "document array shape: (93719, 100, 21)\n",
      "documents saved\n",
      "everything done in 932.11\n"
     ]
    }
   ],
   "source": [
    "!python ./experiments/preprocessing_baseline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same architecture but far bigger document.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33995, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33995 to 0.31840, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31840 to 0.26294, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26294 to 0.25565, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.25565 to 0.24104, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24104\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24104 to 0.22166, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.22166 to 0.20538, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20538 to 0.20000, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20000 to 0.18068, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18068\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.18068 to 0.17697, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17697 to 0.17595, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_0\n",
      "* * * * * * * target 0 done * * * * * * *\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16099, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_1\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16099 to 0.13599, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_1\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13599 to 0.12750, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_1\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12750\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12750 to 0.11175, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_1\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11175\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11175\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11175 to 0.10797, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_1\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10797 to 0.10437, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_1\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10437\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.10437 to 0.09373, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_1\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09373\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.09373\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09373 to 0.08637, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_1\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08637\n",
      "* * * * * * * target 1 done * * * * * * *\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52935, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52935 to 0.50132, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.50132 to 0.48561, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.48561 to 0.46876, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.46876 to 0.46817, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46817 to 0.45302, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45302 to 0.43351, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.43351\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.43351 to 0.42577, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.42577 to 0.39780, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.39780\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.39780\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.39780\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.39780\n",
      "* * * * * * * target 2 done * * * * * * *\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25673, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25673 to 0.25501, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25501 to 0.22873, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22873 to 0.22183, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22183\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.22183 to 0.21622, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21622 to 0.21544, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21544\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21544\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21544\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.21544 to 0.21173, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.21173 to 0.21077, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.21077 to 0.20633, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.20633 to 0.18879, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.18879 to 0.16105, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_3\n",
      "* * * * * * * target 3 done * * * * * * *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!python ./experiments/adding_layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!python ./read_results_predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : baseline architecture (linear activation) + baseline embeddings\n",
    "\n",
    "target 0 : ok\n",
    "les autres à tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target 2 is overfitting... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to retrain one specific target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59980 samples, validate on 14995 samples\n",
      "Epoch 1/15\n",
      "59980/59980 [==============================] - 189s 3ms/step - loss: 0.6941 - mean_squared_error: 0.6941 - val_loss: 0.5619 - val_mean_squared_error: 0.5619\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56191, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "Epoch 2/15\n",
      "59980/59980 [==============================] - 185s 3ms/step - loss: 0.5972 - mean_squared_error: 0.5972 - val_loss: 0.5367 - val_mean_squared_error: 0.5367\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56191 to 0.53673, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "Epoch 3/15\n",
      "59980/59980 [==============================] - 193s 3ms/step - loss: 0.5698 - mean_squared_error: 0.5698 - val_loss: 0.5761 - val_mean_squared_error: 0.5761\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.53673\n",
      "Epoch 4/15\n",
      "59980/59980 [==============================] - 197s 3ms/step - loss: 0.5416 - mean_squared_error: 0.5416 - val_loss: 0.5334 - val_mean_squared_error: 0.5334\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.53673 to 0.53339, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "Epoch 5/15\n",
      "59980/59980 [==============================] - 197s 3ms/step - loss: 0.5277 - mean_squared_error: 0.5277 - val_loss: 0.5255 - val_mean_squared_error: 0.5255\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53339 to 0.52548, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "Epoch 6/15\n",
      "59980/59980 [==============================] - 201s 3ms/step - loss: 0.5138 - mean_squared_error: 0.5138 - val_loss: 0.4906 - val_mean_squared_error: 0.4906\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52548 to 0.49062, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "Epoch 7/15\n",
      "59980/59980 [==============================] - 201s 3ms/step - loss: 0.5017 - mean_squared_error: 0.5017 - val_loss: 0.4617 - val_mean_squared_error: 0.4617\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49062 to 0.46172, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "Epoch 8/15\n",
      "59980/59980 [==============================] - 205s 3ms/step - loss: 0.4942 - mean_squared_error: 0.4942 - val_loss: 0.4693 - val_mean_squared_error: 0.4693\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.46172\n",
      "Epoch 9/15\n",
      "59980/59980 [==============================] - 209s 3ms/step - loss: 0.4811 - mean_squared_error: 0.4811 - val_loss: 0.4510 - val_mean_squared_error: 0.4510\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.46172 to 0.45104, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "Epoch 10/15\n",
      "59980/59980 [==============================] - 204s 3ms/step - loss: 0.4759 - mean_squared_error: 0.4759 - val_loss: 0.4292 - val_mean_squared_error: 0.4292\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45104 to 0.42921, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad/data/model_2\n",
      "Epoch 11/15\n",
      "59980/59980 [==============================] - 203s 3ms/step - loss: 0.4716 - mean_squared_error: 0.4716 - val_loss: 0.4585 - val_mean_squared_error: 0.4585\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42921\n",
      "Epoch 12/15\n",
      "59980/59980 [==============================] - 204s 3ms/step - loss: 0.4650 - mean_squared_error: 0.4650 - val_loss: 0.4462 - val_mean_squared_error: 0.4462\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.42921\n",
      "Epoch 13/15\n",
      "59980/59980 [==============================] - 204s 3ms/step - loss: 0.4574 - mean_squared_error: 0.4574 - val_loss: 0.4317 - val_mean_squared_error: 0.4317\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.42921\n",
      "Epoch 14/15\n",
      "59980/59980 [==============================] - 199s 3ms/step - loss: 0.4539 - mean_squared_error: 0.4539 - val_loss: 0.4474 - val_mean_squared_error: 0.4474\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.42921\n",
      "* * * * * * * target 2 done * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, GRU, CuDNNGRU, TimeDistributed, Dense\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "\n",
    "is_GPU = False\n",
    "save_weights = True\n",
    "save_history = False\n",
    "np.random.seed(1997)\n",
    "\n",
    "path_root = 'D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/Altegrad'\n",
    "path_to_code = path_root + '/code/'\n",
    "path_to_data = path_root + '/data/'\n",
    "\n",
    "sys.path.insert(0, path_to_code)\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "from AttentionWithContext import AttentionWithContext\n",
    "from make_model import make_model\n",
    "\n",
    "\n",
    "# = = = = = hyper-parameters = = = = =\n",
    "\n",
    "tgt = 2\n",
    "n_units = 80\n",
    "drop_rate = 0.5\n",
    "batch_size = 96\n",
    "nb_epochs = 15\n",
    "my_optimizer = 'adam'\n",
    "my_patience = 4\n",
    "\n",
    "# = = = = = data loading = = = = =\n",
    "\n",
    "docs = np.load(path_to_data + 'documents.npy')\n",
    "embeddings = np.load(path_to_data + 'embeddings.npy')\n",
    "\n",
    "with open(path_to_data + 'train_idxs.txt', 'r') as file:\n",
    "    train_idxs = file.read().splitlines()\n",
    "    \n",
    "train_idxs = [int(elt) for elt in train_idxs]\n",
    "    \n",
    "# create validation set\n",
    "\n",
    "idxs_select_train = np.random.choice(range(len(train_idxs)), size=int(len(train_idxs) * 0.80), replace=False)\n",
    "idxs_select_val = np.setdiff1d(range(len(train_idxs)), idxs_select_train)\n",
    "\n",
    "train_idxs_new = [train_idxs[elt] for elt in idxs_select_train]\n",
    "val_idxs = [train_idxs[elt] for elt in idxs_select_val]\n",
    "\n",
    "docs_train = docs[train_idxs_new, :, :]\n",
    "docs_val = docs[val_idxs, :, :]\n",
    "\n",
    "\n",
    "with open(path_to_data + 'targets/train/target_' + str(tgt) + '.txt', 'r') as file:\n",
    "    target = file.read().splitlines()\n",
    "    \n",
    "target_train = np.array([target[elt] for elt in idxs_select_train]).astype('float')\n",
    "target_val = np.array([target[elt] for elt in idxs_select_val]).astype('float')\n",
    "\n",
    "# target 2 is over fitting so maybe try more units and dropout -> more expressivity    \n",
    "\n",
    "model = make_model(n_units, drop_rate, embeddings, docs_train, is_GPU)\n",
    " \n",
    "model.compile(loss='mean_squared_error',\n",
    "                  optimizer=my_optimizer,\n",
    "                  metrics=['mse'])\n",
    "\n",
    "# = = = = = training = = = = =\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                   patience=my_patience,\n",
    "                                   mode='min')\n",
    "\n",
    "    # save model corresponding to best epoch\n",
    "checkpointer = ModelCheckpoint(filepath=path_to_data + 'model_' + str(tgt), \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=True)\n",
    "\n",
    "if save_weights:\n",
    "    my_callbacks = [early_stopping, checkpointer]\n",
    "else:\n",
    "    my_callbacks = [early_stopping]\n",
    "\n",
    "model.fit(docs_train, \n",
    "              target_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = nb_epochs,\n",
    "              validation_data = (docs_val, target_val),\n",
    "              callbacks = my_callbacks)\n",
    "    \n",
    "\n",
    "if save_history:\n",
    "    hist = model.history.history\n",
    "    with open(path_to_data + 'model_history_' + str(tgt) + '.json', 'w') as file:\n",
    "        json.dump(hist, file, sort_keys=False, indent=4)\n",
    "\n",
    "print('* * * * * * * target', tgt, 'done * * * * * * *')    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
