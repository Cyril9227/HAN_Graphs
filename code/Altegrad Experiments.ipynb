{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altegrad Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TO TRAIN ONE TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 70, 11)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 70, 60)            21972855  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 70, 60)            43920     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 60)                3720      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 22,024,216\n",
      "Trainable params: 107,581\n",
      "Non-trainable params: 21,916,635\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 59980 samples, validate on 14995 samples\n",
      "Epoch 1/60\n",
      "59980/59980 [==============================] - 32s 536us/step - loss: 0.3410 - mean_squared_error: 0.3410 - val_loss: 0.1909 - val_mean_squared_error: 0.1909\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19094, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 2/60\n",
      "59980/59980 [==============================] - 35s 576us/step - loss: 0.1766 - mean_squared_error: 0.1766 - val_loss: 0.1831 - val_mean_squared_error: 0.1831 mean_squa - ETA: 3s - loss: 0.1786 - mean_s - ETA: 0s - loss: 0.1771 - mean_squared_error:  - ETA: 0s - loss: 0.1771 - mean_squared\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19094 to 0.18306, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 3/60\n",
      "59980/59980 [==============================] - 34s 562us/step - loss: 0.1500 - mean_squared_error: 0.1500 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.18306 to 0.13197, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 4/60\n",
      "59980/59980 [==============================] - 34s 568us/step - loss: 0.1373 - mean_squared_error: 0.1373 - val_loss: 0.1207 - val_mean_squared_error: 0.1207\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.13197 to 0.12065, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 5/60\n",
      "59980/59980 [==============================] - 35s 590us/step - loss: 0.1285 - mean_squared_error: 0.1285 - val_loss: 0.1088 - val_mean_squared_error: 0.1088\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12065 to 0.10878, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 6/60\n",
      "59980/59980 [==============================] - 35s 585us/step - loss: 0.1219 - mean_squared_error: 0.1219 - val_loss: 0.1169 - val_mean_squared_error: 0.1169\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10878\n",
      "Epoch 7/60\n",
      "59980/59980 [==============================] - 33s 550us/step - loss: 0.1180 - mean_squared_error: 0.1180 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10878 to 0.10267, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 8/60\n",
      "59980/59980 [==============================] - 30s 508us/step - loss: 0.1123 - mean_squared_error: 0.1123 - val_loss: 0.1076 - val_mean_squared_error: 0.1076\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10267\n",
      "Epoch 9/60\n",
      "59980/59980 [==============================] - 31s 523us/step - loss: 0.1092 - mean_squared_error: 0.1092 - val_loss: 0.0974 - val_mean_squared_error: 0.0974\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10267 to 0.09740, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 10/60\n",
      "59980/59980 [==============================] - 32s 529us/step - loss: 0.1050 - mean_squared_error: 0.1050 - val_loss: 0.1027 - val_mean_squared_error: 0.102754  - ETA: 0s - loss: 0.1051 - mean_squared\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09740\n",
      "Epoch 11/60\n",
      "59980/59980 [==============================] - 32s 534us/step - loss: 0.1018 - mean_squared_error: 0.1018 - val_loss: 0.0995 - val_mean_squared_error: 0.0995\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.09740\n",
      "Epoch 12/60\n",
      "59980/59980 [==============================] - 32s 538us/step - loss: 0.0986 - mean_squared_error: 0.0986 - val_loss: 0.0915 - val_mean_squared_error: 0.0915\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09740 to 0.09151, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 13/60\n",
      "59980/59980 [==============================] - 33s 543us/step - loss: 0.0969 - mean_squared_error: 0.0969 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.09151 to 0.09016, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 14/60\n",
      "59980/59980 [==============================] - 33s 546us/step - loss: 0.0924 - mean_squared_error: 0.0924 - val_loss: 0.0857 - val_mean_squared_error: 0.0857\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09016 to 0.08566, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 15/60\n",
      "59980/59980 [==============================] - 33s 550us/step - loss: 0.0896 - mean_squared_error: 0.0896 - val_loss: 0.0806 - val_mean_squared_error: 0.0806\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08566 to 0.08058, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 16/60\n",
      "59980/59980 [==============================] - 34s 569us/step - loss: 0.0868 - mean_squared_error: 0.0868 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.08058\n",
      "Epoch 17/60\n",
      "59980/59980 [==============================] - 34s 569us/step - loss: 0.0857 - mean_squared_error: 0.0857 - val_loss: 0.0842 - val_mean_squared_error: 0.0842\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08058\n",
      "Epoch 18/60\n",
      "59980/59980 [==============================] - 34s 569us/step - loss: 0.0831 - mean_squared_error: 0.0831 - val_loss: 0.0791 - val_mean_squared_error: 0.0791\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08058 to 0.07909, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 19/60\n",
      "59980/59980 [==============================] - 35s 584us/step - loss: 0.0819 - mean_squared_error: 0.0819 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07909\n",
      "Epoch 20/60\n",
      "59980/59980 [==============================] - 35s 591us/step - loss: 0.0790 - mean_squared_error: 0.0790 - val_loss: 0.0787 - val_mean_squared_error: 0.0787\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.07909 to 0.07866, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 21/60\n",
      "59980/59980 [==============================] - 36s 593us/step - loss: 0.0780 - mean_squared_error: 0.0780 - val_loss: 0.0797 - val_mean_squared_error: 0.0797\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07866\n",
      "Epoch 22/60\n",
      "59980/59980 [==============================] - 36s 603us/step - loss: 0.0777 - mean_squared_error: 0.0777 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07866\n",
      "Epoch 23/60\n",
      "59980/59980 [==============================] - 34s 572us/step - loss: 0.0748 - mean_squared_error: 0.0748 - val_loss: 0.0751 - val_mean_squared_error: 0.0751\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07866 to 0.07509, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 24/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59980/59980 [==============================] - 33s 546us/step - loss: 0.0727 - mean_squared_error: 0.0727 - val_loss: 0.0758 - val_mean_squared_error: 0.0758\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07509\n",
      "Epoch 25/60\n",
      "59980/59980 [==============================] - 33s 548us/step - loss: 0.0723 - mean_squared_error: 0.0723 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.07509 to 0.07385, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 26/60\n",
      "59980/59980 [==============================] - 33s 551us/step - loss: 0.0700 - mean_squared_error: 0.0700 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07385\n",
      "Epoch 27/60\n",
      "59980/59980 [==============================] - 34s 562us/step - loss: 0.0677 - mean_squared_error: 0.0677 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07385\n",
      "Epoch 28/60\n",
      "59980/59980 [==============================] - 33s 552us/step - loss: 0.0681 - mean_squared_error: 0.0681 - val_loss: 0.0749 - val_mean_squared_error: 0.0749\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.07385\n",
      "Epoch 29/60\n",
      "59980/59980 [==============================] - 34s 566us/step - loss: 0.0677 - mean_squared_error: 0.0677 - val_loss: 0.0727 - val_mean_squared_error: 0.0727\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.07385 to 0.07266, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 30/60\n",
      "59980/59980 [==============================] - 36s 597us/step - loss: 0.0652 - mean_squared_error: 0.0652 - val_loss: 0.0701 - val_mean_squared_error: 0.0701\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.07266 to 0.07010, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 31/60\n",
      "59980/59980 [==============================] - 33s 558us/step - loss: 0.0636 - mean_squared_error: 0.0636 - val_loss: 0.0725 - val_mean_squared_error: 0.0725\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07010\n",
      "Epoch 32/60\n",
      "59980/59980 [==============================] - 36s 596us/step - loss: 0.0632 - mean_squared_error: 0.0632 - val_loss: 0.0684 - val_mean_squared_error: 0.0684\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.07010 to 0.06838, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 33/60\n",
      "59980/59980 [==============================] - 33s 552us/step - loss: 0.0624 - mean_squared_error: 0.0624 - val_loss: 0.0705 - val_mean_squared_error: 0.0705\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06838\n",
      "Epoch 34/60\n",
      "59980/59980 [==============================] - 35s 580us/step - loss: 0.0627 - mean_squared_error: 0.0627 - val_loss: 0.0738 - val_mean_squared_error: 0.0738\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06838\n",
      "Epoch 35/60\n",
      "59980/59980 [==============================] - 35s 582us/step - loss: 0.0626 - mean_squared_error: 0.0626 - val_loss: 0.0717 - val_mean_squared_error: 0.0717\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06838\n",
      "Epoch 36/60\n",
      "59980/59980 [==============================] - 34s 573us/step - loss: 0.0592 - mean_squared_error: 0.0592 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06838\n",
      "Epoch 37/60\n",
      "59980/59980 [==============================] - 33s 557us/step - loss: 0.0597 - mean_squared_error: 0.0597 - val_loss: 0.0710 - val_mean_squared_error: 0.0710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06838\n",
      "Epoch 38/60\n",
      "59980/59980 [==============================] - 34s 567us/step - loss: 0.0575 - mean_squared_error: 0.0575 - val_loss: 0.0679 - val_mean_squared_error: 0.0679\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.06838 to 0.06788, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 39/60\n",
      "59980/59980 [==============================] - 33s 558us/step - loss: 0.0575 - mean_squared_error: 0.0575 - val_loss: 0.0684 - val_mean_squared_error: 0.0684\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06788\n",
      "Epoch 40/60\n",
      "59980/59980 [==============================] - 36s 595us/step - loss: 0.0562 - mean_squared_error: 0.0562 - val_loss: 0.0695 - val_mean_squared_error: 0.0695\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.06788\n",
      "Epoch 41/60\n",
      "59980/59980 [==============================] - 36s 599us/step - loss: 0.0564 - mean_squared_error: 0.0564 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.06788 to 0.06572, saving model to D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/model_1\n",
      "Epoch 42/60\n",
      "59980/59980 [==============================] - 34s 569us/step - loss: 0.0553 - mean_squared_error: 0.0553 - val_loss: 0.0680 - val_mean_squared_error: 0.0680\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06572\n",
      "Epoch 43/60\n",
      "59980/59980 [==============================] - 37s 612us/step - loss: 0.0546 - mean_squared_error: 0.0546 - val_loss: 0.0669 - val_mean_squared_error: 0.0669\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06572\n",
      "Epoch 44/60\n",
      "59980/59980 [==============================] - 36s 602us/step - loss: 0.0538 - mean_squared_error: 0.0538 - val_loss: 0.0658 - val_mean_squared_error: 0.0658\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06572\n",
      "Epoch 45/60\n",
      "59980/59980 [==============================] - 36s 603us/step - loss: 0.0541 - mean_squared_error: 0.0541 - val_loss: 0.0687 - val_mean_squared_error: 0.0687\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.06572\n",
      "Epoch 46/60\n",
      "59980/59980 [==============================] - 35s 591us/step - loss: 0.0538 - mean_squared_error: 0.0538 - val_loss: 0.0663 - val_mean_squared_error: 0.0663\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.06572\n",
      "Epoch 47/60\n",
      "59980/59980 [==============================] - 35s 590us/step - loss: 0.0531 - mean_squared_error: 0.0531 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.06572\n",
      "* * * * * * * target 1 done * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, GRU, CuDNNGRU, TimeDistributed, Dense\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "tgt = 1\n",
    "\n",
    "is_GPU = True\n",
    "save_hist = False\n",
    "save_weights = True\n",
    "path_root = os.path.dirname(os.path.abspath('').replace('\\\\', '/'))\n",
    "path_to_data = path_root + '/data/'\n",
    "path_to_code = path_root + '/code/experiments/target_' + str(tgt) + '/'\n",
    "sys.path.insert(0, path_to_code)\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "from AttentionWithContext import AttentionWithContext\n",
    "from make_model_tgt1 import make_model\n",
    "\n",
    "# = = = = = hyper-parameters = = = = =\n",
    "\n",
    "\n",
    "n_units = 60\n",
    "drop_rate = 0.1\n",
    "batch_size = 96\n",
    "nb_epochs = 60\n",
    "my_optimizer = 'adam'\n",
    "my_patience = 6\n",
    "\n",
    "# = = = = = data loading = = = = =\n",
    "\n",
    "docs = np.load(path_to_data + 'documents.npy')\n",
    "embeddings = np.load(path_to_data + 'embeddings.npy')\n",
    "\n",
    "with open(path_to_data + 'train_idxs.txt', 'r') as file:\n",
    "    train_idxs = file.read().splitlines()\n",
    "    \n",
    "train_idxs = [int(elt) for elt in train_idxs]\n",
    "\n",
    "idxs_select_train = np.random.choice(range(len(train_idxs)), size=int(len(train_idxs) * 0.80), replace=False)\n",
    "idxs_select_val = np.setdiff1d(range(len(train_idxs)), idxs_select_train)\n",
    "\n",
    "train_idxs_new = [train_idxs[elt] for elt in idxs_select_train]\n",
    "val_idxs = [train_idxs[elt] for elt in idxs_select_val]\n",
    "\n",
    "docs_train = docs[train_idxs_new, :, :]\n",
    "docs_val = docs[val_idxs, :, :]\n",
    "\n",
    "\n",
    "with open(path_to_data + 'targets/train/target_' + str(tgt) + '.txt', 'r') as file:\n",
    "    target = file.read().splitlines()\n",
    "    \n",
    "target_train = np.array([target[elt] for elt in idxs_select_train]).astype('float')\n",
    "target_val = np.array([target[elt] for elt in idxs_select_val]).astype('float')\n",
    "\n",
    "model = make_model(n_units, drop_rate, embeddings, docs_train, is_GPU)\n",
    "print(model.summary())\n",
    " \n",
    "model.compile(loss='mean_squared_error',\n",
    "                  optimizer=my_optimizer,\n",
    "                  metrics=['mse'])\n",
    "\n",
    "# = = = = = training = = = = =\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                   patience=my_patience,\n",
    "                                   mode='min')\n",
    "\n",
    "# save model corresponding to best epoch\n",
    "checkpointer = ModelCheckpoint(filepath=path_to_data + 'model_' + str(tgt), \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=True)\n",
    "\n",
    "if save_weights:\n",
    "    my_callbacks = [early_stopping, checkpointer]\n",
    "else:\n",
    "    my_callbacks = [early_stopping]\n",
    "\n",
    "model.fit(docs_train, \n",
    "              target_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = nb_epochs,\n",
    "              validation_data = (docs_val, target_val),\n",
    "              callbacks = my_callbacks)\n",
    "    \n",
    "\n",
    "if save_hist:\n",
    "    hist = model.history.history\n",
    "    with open(path_to_data + 'model_history_' + str(tgt) + '.json', 'w') as file:\n",
    "        json.dump(hist, file, sort_keys=False, indent=4)\n",
    "\n",
    "print('* * * * * * * target', tgt, 'done * * * * * * *')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TO PREDICT ONE TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, GRU, CuDNNGRU, TimeDistributed, Dense\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "tgt = 1\n",
    "\n",
    "is_GPU = True\n",
    "save_hist = False\n",
    "path_root = os.path.dirname(os.path.abspath('').replace('\\\\', '/'))\n",
    "path_to_data = path_root + '/data/'\n",
    "path_to_code = path_root + '/code/experiments/target_' + str(tgt) + '/'\n",
    "sys.path.insert(0, path_to_code)\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "from AttentionWithContext import AttentionWithContext\n",
    "# to change \n",
    "from make_model_tgt1 import make_model\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "docs = np.load(path_to_data + 'documents.npy')\n",
    "embeddings = np.load(path_to_data + 'embeddings.npy')\n",
    "\n",
    "with open(path_to_data + 'test_idxs.txt', 'r') as file:\n",
    "    test_idxs = file.read().splitlines()\n",
    "\n",
    "\n",
    "test_idxs = [int(elt) for elt in test_idxs]\n",
    "docs_test = docs[test_idxs,:,:]\n",
    "\n",
    "all_preds_han = []\n",
    "\n",
    "indx_tg0 = [i for i in range(0, 18744)]\n",
    "indx_tg1 = [i for i in range(18744, 37488)]\n",
    "indx_tg2 = [i for i in range(37488, 56232)]\n",
    "indx_tg3 = [i for i in range(56232,74976)]\n",
    "\n",
    "idx = [indx_tg0, indx_tg1, indx_tg2, indx_tg3]\n",
    "\n",
    "# * * * HAN * * * \n",
    "    \n",
    "# relevant hyper-parameters\n",
    "n_units = 60\n",
    "drop_rate = 0 # prediction mode\n",
    " \n",
    "model = make_model(n_units, drop_rate, embeddings, docs_test, is_GPU)\n",
    "    \n",
    "model.load_weights(path_to_data + 'model_' + str(tgt))\n",
    "all_preds_han.append(model.predict(docs_test).tolist())\n",
    "\n",
    "# flatten\n",
    "all_preds_han = [elt[0] for sublist in all_preds_han for elt in sublist]\n",
    "\n",
    "# write the predictions of a single target with the corrects indx\n",
    "with open(path_to_data + 'predictions_han_' + str(tgt) + '.txt', 'w') as file:\n",
    "    for idx, pred in zip(idx[tgt], all_preds_han):\n",
    "        if tgt==0:\n",
    "            file.write('id,pred\\n')\n",
    "        pred = format(pred, '.7f')\n",
    "        file.write(str(idx) + ',' + pred + '\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate predictions of all targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def from_txt_to_csv(file_name, folder_name):\n",
    "    \"\"\"\n",
    "    Transform the output of the read_results_predict.py in a proper Kaggle Submission, i.e : a well formated csv file\n",
    "    \n",
    "    inputs : \n",
    "    - file_name is the name (string) of the txt file generated by the read_results_predict.py (without the .txt extension)\n",
    "    - folder_name is the desired or existing name (string) of the folder where the submission will be stored into \n",
    "    \n",
    "    output : None\n",
    "    \n",
    "    \"\"\"\n",
    "    # change me !\n",
    "    path_root = os.path.dirname(os.path.abspath('').replace('\\\\', '/')) + \"/data/\"\n",
    "    path_file = path_root  + file_name + \".txt\"\n",
    "    path_folder = path_root + folder_name\n",
    "    # create a directory if it doesn't exist yet\n",
    "    if not os.path.exists(path_folder):\n",
    "        os.makedirs(path_folder)\n",
    "      \n",
    "    df = pd.read_csv(path_file)\n",
    "    df.to_csv(path_folder + \"/\" + file_name + \".csv\", index=False)\n",
    "    print(\"Submission saved in '{}'\".format(path_folder))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved in 'D:/Scolaire/Code/Python/Machine_Learning/Kaggle_Challenges_M2/HAN_Graphs/data/'\n"
     ]
    }
   ],
   "source": [
    "# list of txt files containing predictions for each target\n",
    "filenames = [path_to_data + 'predictions_han_' + str(tgt) + '.txt' for tgt in range(4)]\n",
    "with open(path_to_data + 'predictions_all.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "\n",
    "from_txt_to_csv('predictions_all', '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
